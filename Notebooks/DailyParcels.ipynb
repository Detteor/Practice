{
 "cells": [
  {
   "source": [
    "# Daily Task to Update the Tax Parcels Feature Class\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " <b> TO DO: </b>\n",
    " <ul>         \n",
    "        <li>Do not use arc.env.workspace Environment Variables.</li>\n",
    "        <li>Truncate and Append Tax Exempt to PROD.gisadmin.TaxExempt.</li>\n",
    "        <li>Truncate and Append Tax Parcels to PROD.gisadmin.TaxParcels.</li>\n",
    "        <li>Truncate and Append Historical Parcels to PROD.gisadmin.TaxParcels.</li>\n",
    "        \n",
    "        \n",
    "         </ul> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Import modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arcpy as arc\n",
    "from arcpy import env\n",
    "from arcgis.gis import GIS\n",
    "from arcgis import features\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path"
   ]
  },
  {
   "source": [
    "### Create Folders in the Users Directory since it should have r/w permissions for the user."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc.env.overwriteOutput = True\n",
    "arc.env.qualifiedFieldNames = False\n",
    "arc.env.outputZFlag = 'Disabled' #To remove z data from parcel fabric due to it being a polygonZ\n",
    "arc.env.outputMFlag = 'Disabled'\n",
    "now = dt.today()\n",
    "mStr = now.strftime('%m%Y')\n",
    "dStr = now.strftime('%m_%d')\n",
    "wStr = now.strftime('%U')\n",
    "uPath = Path.home()\n",
    "locFolders = ['Processing', 'Review']\n",
    "if uPath.exists():\n",
    "    for x in locFolders:\n",
    "        a = Path(uPath / 'GIS' / x)\n",
    "        if a.exists():\n",
    "            print(f'{a} already exists.')\n",
    "        else:\n",
    "            a.mkdir(parents=True)\n",
    "            print(f'{a} has been created.')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "gisPath = uPath / 'GIS'\n",
    "lPath = [f for f in gisPath.glob('*')]\n",
    "netDir = Path(r'\\\\kcdp-1\\KCGIS\\MasterGISFiles\\Ben')\n",
    "netDB = netDir / 'GISPro' / 'SDE Connections'"
   ]
  },
  {
   "source": [
    "### Only use with notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "source": [
    "### Create File GeoDatabase and Feature Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Folders for Permits Data\n",
    "paFolder = [f for f in lPath if f.name == 'Processing'][0]\n",
    "paProcessing = paFolder / 'Parcels' / f'{dStr}'\n",
    "if paProcessing.exists() == True:\n",
    "    print(f'{paProcessing} already exist.')\n",
    "else:\n",
    "    paProcessing.mkdir(parents=True)\n",
    "    print(f'Created {paProcessing}.')\n",
    "\n",
    "paFR = [f for f in lPath if f.name == 'Review'][0]\n",
    "paReview = paFR / 'Parcels' / f'{dStr}'\n",
    "if paReview.exists() == True:\n",
    "    print(f'{paReview} already exist')\n",
    "else:\n",
    "    paReview.mkdir(parents=True)\n",
    "    print(f'Created {paReview}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iE = netDB / 'MAPPINGADMIN.sde' / 'PROD.MAPPINGADMIN.ParcelEditing'\n",
    "sr = arc.Describe(f'{iE}').spatialReference\n",
    "outGDB = gisPath / paFolder / f'Data_{mStr}.gdb'\n",
    "# dsA = gisPath / pFolder / f'{outGDB}.gdb'\n",
    "locGDB = outGDB / f'Daily_{dStr}'\n",
    "if arc.Exists(f'{outGDB}'):\n",
    "    print(\"GDB already exists.\")\n",
    "else:\n",
    "    arc.CreateFileGDB_management(f'{paFolder}', f'{outGDB.name}')\n",
    "    print(f'Created File GeoDatabase at {outGDB.parent}')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "if arc.Exists(f'{locGDB}'):\n",
    "    print(f'{locGDB.name} already exists')\n",
    "else:\n",
    "    arc.CreateFeatureDataset_management(f'{locGDB.parent}', f'{locGDB.name}', sr)\n",
    "    print(f'{locGDB.name} Dataset has been created')"
   ]
  },
  {
   "source": [
    "### Does not work with Parcel Fabric due to bug with 10.5.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbOwnTab = 'PROD.gisadmin.OWNERSHIPINFORMATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create paths to the data instead of using env.workspace makes it so that I can use arc Walk\n",
    "arc.env.workspace = f'{iE.parent}'\n",
    "tList = dbOwnTab\n",
    "cParcels = []\n",
    "cTables = []\n",
    "for dirpath, dirnames, filenames in arc.da.Walk():\n",
    "    for f in filenames:\n",
    "        if f in tList:\n",
    "            a  = f.split('.')[-1]\n",
    "            b = f'{a}_{dStr}' #Tables need to have a date string since they won't be under the dataset\n",
    "            # c = locGDB.parent\n",
    "            if arc.Exists(f'{outGDB / b}'):\n",
    "                cTables.append(outGDB.joinpath(b))\n",
    "                print(f'{b} already exists')\n",
    "            else:\n",
    "                arc.TableToTable_conversion(f, f'{outGDB}', f'{b}')\n",
    "                cTables.append(outGDB.joinpath(b))\n",
    "                print (f'{b} has been copied')"
   ]
  },
  {
   "source": [
    "### Works with Parcel Fabric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently using env.workspace to move parcelfabric needs to be changed to use path\n",
    "pfParcels = 'PROD.MAPPINGADMIN.ParcelFabric_Parcels'\n",
    "dbPFPlan = 'PROD.MAPPINGADMIN.ParcelFabric_Plans'\n",
    "exp = \"TYPE = 7 AND Historical = 0\"\n",
    "a = pfParcels.split('.')[-1]\n",
    "b = f'{a}_{dStr}'\n",
    "# print(f'{iEPath[1]}')\n",
    "if arc.Exists(f'{locGDB / b}'):\n",
    "    cParcels.append(locGDB.joinpath(b))\n",
    "    print(f'{b} already exists')\n",
    "else:\n",
    "    print(f'Copying Parcel Fabric to {locGDB.name}')\n",
    "    #print(a)\n",
    "    # g = f'{f}'\n",
    "    #print(g)\n",
    "    arc.FeatureClassToFeatureClass_conversion(pfParcels, f'{locGDB}', b, where_clause=exp)\n",
    "    cParcels.append(locGDB.joinpath(b))\n",
    "    print(f'Finished Copying {b} to {locGDB.name}')\n",
    "#Copy parcel Fabric plans table to local GDB\n",
    "c = dbPFPlan.split('.')[-1]\n",
    "d = f'{c}_{dStr}'\n",
    "if arc.Exists(f'{outGDB / d}'):\n",
    "    cTables.append(outGDB.joinpath(d))\n",
    "    print(f'{d} already exists')\n",
    "else:\n",
    "    print(f'Copying {d} to {outGDB.name}')\n",
    "    arc.TableToTable_conversion(dbPFPlan, f'{outGDB}', d)\n",
    "    cTables.append(outGDB.joinpath(d))\n",
    "    print(f'Finised Copying {d} to {outGDB.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataFarame from the current Parcels\n",
    "pfFC = [f for f in cParcels if f.name.startswith('ParcelFabric') == True][0]\n",
    "pf_df = features.GeoAccessor.from_featureclass(pfFC, fields=['Name', 'Pride', 'Lot_Number', 'Plat_Book','Parent'])\n",
    "pf_df.Name = pf_df.Name.apply(lambda x: x.strip())\n",
    "print('Parcel Fabric DataFrame created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the 1 values from Parcel Fabric\n",
    "pf_df = pf_df[pf_df.Name != '1'].copy(deep=True)"
   ]
  },
  {
   "source": [
    "Use to Create the Historical Parcels Feature Class on esridb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently using env.workspace to move parcelfabric needs to be changed to use path\n",
    "exp = \"TYPE = 7 AND Historical = 1\"\n",
    "ah = pfParcels.split('.')[-1]\n",
    "bh = f'H{a}_{dStr}'\n",
    "if arc.Exists(f'{locGDB / bh}'):\n",
    "    cParcels.append(locGDB.joinpath(b))\n",
    "    print(f'{bh} already exists')\n",
    "else:\n",
    "    print(f'Copying {bh} to {locGDB.name}')\n",
    "    arc.FeatureClassToFeatureClass_conversion(pfParcels, f'{locGDB}', bh, where_clause=exp)\n",
    "    cParcels.append(locGDB.joinpath(bh))\n",
    "    print(f'Finished Copying {bh} to {locGDB.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataFrame from the historical Parcels\n",
    "hpfFC = [f for f in cParcels if f.name.startswith('HParcelFabric') == True][0]\n",
    "hdf = features.GeoAccessor.from_featureclass(hpfFC, fields=['Name', 'HistoryType', 'Lot_Number', 'Plat_Book', 'Parent'])\n",
    "hdf.Name = hdf.Name.apply(lambda x: x.strip()) #Remove whitespace\n",
    "print('Historic Parcel Fabric DataFrame created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the 1 values from Name column\n",
    "ehdf = hdf[hdf.Name != '1'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the new data to esridb feature class\n",
    "dbOut = netDB / \"PROD-GISADMIN.sde\" / 'PROD.GISADMIN.Parcel_Information' / 'PROD.GISADMIN.HistoricParcel'\n",
    "hOut = locGDB / f'HParcels_{dStr}'\n",
    "print(f'Exporting {hOut.name} to {locGDB.name}')\n",
    "ehdf.spatial.to_featureclass(str(hOut), sanitize_columns=False)\n",
    "print('Finished Exporting')\n",
    "print('Truncating and Appending to HParcels on esridb')\n",
    "arc.TruncateTable_management(f'{dbOut}')\n",
    "arc.Append_management(f'{hOut}', f'{dbOut}', schema_type='NO_TEST')\n",
    "print(\"Finished adding new data to esridb\")\n",
    "del hdf #This deletes the historic parcels dataframe so it will clear up RAM"
   ]
  },
  {
   "source": [
    "Prepare Ownership Table for join with Parcel Fabric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oTab = [f for f in cTables if f.name.startswith('OWNER') == True][0]\n",
    "ot = features.GeoAccessor.from_table(f'{oTab}', fields=['PARCELID','LOCATION', 'OWNERNAME', 'SECONDARYOWNER', 'MAILINGADDRESS','MAILINGADDRESS2','OWNERCITY','OWNERSTATE','OWNERZIP','DEEDREFERENCE','DEEDACREAGE','LANDASSESSMENT','IMPROVE','TOTALASSESSMENT','LOCATIONID','YEARBUILT','PROPERTYUSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oMerge = pf_df.merge(ot, how='outer', right_on='PARCELID', left_on='Name', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Parcels that don't match\n",
    "nM = paReview / 'Parcels_Missing.csv' \n",
    "oMerge[(oMerge._merge == 'right_only') & (oMerge.PARCELID.str.contains('-00001', na=False))].to_csv(nM, index=False) #Export parcels with -00001 that don't match, excludes different suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oMerge.reset_index(drop=True, inplace=True)\n",
    "oMerge = oMerge[(oMerge._merge == 'both') & (oMerge.SHAPE.notnull())].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parcels that should possibly be combined\n",
    "combPar = paReview / 'MergeParcels.csv'\n",
    "oMerge[oMerge.Name.duplicated() == True].to_csv(combPar, index=False)\n",
    "oMerge.drop(columns='_merge', inplace=True)"
   ]
  },
  {
   "source": [
    "Prepare Parcel Fabric Plans Table for join with Ownership and Parcel Fabric (oMerge)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfTab = [f for f in cTables if f.name.startswith('ParcelFabric') == True][0]\n",
    "pft = features.GeoAccessor.from_table(f'{pfTab}', fields=['Name','Description', 'Surveyor', 'Company', 'SurveyDate', 'LegalDate', 'ModifyDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplicates from Parcel Fabric Plans\n",
    "parDups = paReview / 'Plans_Dups.csv'\n",
    "pft[pft.Name.duplicated(keep=False)].to_csv(parDups, index=False)\n",
    "\n",
    "pft.sort_values(by='ModifyDate', inplace=True)\n",
    "pft.drop_duplicates(subset=['Name'], keep='last', inplace=True)\n",
    "pft.drop(columns='ModifyDate', inplace=True)\n",
    "pft.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfOMerge = oMerge.merge(pft, how='outer', left_on='Plat_Book', right_on='Name', indicator=True)\n",
    "bPf = pfOMerge[pfOMerge._merge != 'right_only'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Plat Books that don't match or missing\n",
    "planNM = paReview / 'Missing_Plans.csv'\n",
    "pfOMerge[pfOMerge._merge == 'right_only'].to_csv(planNM, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data types of the columns to match the values that it contains\n",
    "ftype = {'TOTALASSESSMENT' : 'int32', 'DEEDACREAGE': 'int32', 'LANDASSESSMENT': 'int32', 'IMPROVE': 'int32', 'LOCATIONID': 'int32', 'YEARBUILT': 'int32'}\n",
    "bPf = bPf[bPf.columns.tolist()].astype(ftype)\n",
    "\n",
    "#drop the additional Name column and rename the other Name column\n",
    "bPf.drop(columns=['Name_y', '_merge'], inplace=True)\n",
    "bPf.rename(columns={'Name_x': 'Name'}, inplace=True)\n",
    "bPf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Fill in the null values\n",
    "bPf.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to local gdb\n",
    "curPar = locGDB / f'Parcels_{dStr}'\n",
    "bPf.spatial.to_featureclass(curPar, sanitize_columns=False)\n",
    "print(f'Finised Exporting {curPar.name} to {locGDB.name}')\n",
    "\n",
    "#Copy to esridb\n",
    "pdbOut = netDB / \"PROD-GISADMIN.sde\" / 'PROD.GISADMIN.Parcel_Information' / 'PROD.GISADMIN.TaxParcel'\n",
    "# arc.FeatureClassToFeatureClass_conversion(str(curPar), f'{pdbOut.parent}', f'{pdbOut.name}')\n",
    "print(f'Truncating and Appending to {pdbOut.name} on esridb')\n",
    "arc.TruncateTable_management(f'{pdbOut}')\n",
    "arc.Append_management(f'{curPar}', f'{pdbOut}', schema_type='NO_TEST')\n",
    "print(\"Finished adding new data to esridb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0be568a45c5be0d4caf76dff1c2f5b3b93950ef2ed99d2899e809934a8a7c9d46",
   "display_name": "Python 3.7.10 64-bit ('arcNew': conda)"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}