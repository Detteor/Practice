{
 "cells": [
  {
   "source": [
    "# MGO Model to Create MGO Feature Service on Kent County REST Server"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<b> Notes: </b>\n",
    "<ul><li>Adopted from Model.py script and MGO model.</li></ul>\n",
    "<b>TO DO:</b>\n",
    "<ul><li> Find Original Model on Danielle's Computer.</li>\n",
    "<li> Need to run the weekly script to make sure all the environmental data is current.</li>\n",
    "\n",
    "\n",
    "\n",
    "</ul>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use arcNew environment with this notebook.\n",
    "#Current Location: C:\\ProgramData\\Anaconda3\\envs\\arcNew\\python.exe\n",
    "import arcpy as arc\n",
    "import os\n",
    "from shutil import copy2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arcgis import features\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\MKinnaman\\GIS\\Processing already exists.\nC:\\Users\\MKinnaman\\GIS\\Review already exists.\n"
     ]
    }
   ],
   "source": [
    "arc.env.overwriteOutput = True\n",
    "arc.env.outputZFlag = 'Disabled' #To remove z data from parcel fabric due to it being a polygonZ \n",
    "arc.env.qualifiedFieldNames = False\n",
    "now = dt.now()\n",
    "mStr = now.strftime('%m%Y')\n",
    "dStr = now.strftime('%m_%d')\n",
    "uPath = Path.home()\n",
    "locFolders = ['Processing', 'Review']\n",
    "if uPath.exists():\n",
    "    for x in locFolders:\n",
    "        a = Path(uPath / 'GIS' / x)\n",
    "        if a.exists():\n",
    "            print(f'{a} already exists.')\n",
    "        else:\n",
    "            a.mkdir(parents=True)\n",
    "            print(f'{a} has been created.')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "gisPath = uPath / 'GIS'\n",
    "lPath = [f for f in gisPath.glob('*')]\n",
    "netDir = Path(r'\\\\kcdp-1\\KCGIS\\MasterGISFiles\\Ben')\n",
    "netDB = netDir / 'GISPro' / 'SDE Connections'\n",
    "# print(netDB)"
   ]
  },
  {
   "source": [
    "### Only use with notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "source": [
    "## Create File GeoDatabase and Feature Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create Directories for MGO Model GDB, for processing, and for Review."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created C:\\Users\\MKinnaman\\GIS\\Processing\\MGO_Model\\05_07.\nCreated C:\\Users\\MKinnaman\\GIS\\Review\\MGO_Model\\05_07\n"
     ]
    }
   ],
   "source": [
    "#Create Folders for MGO Model\n",
    "mFolder = [f for f in lPath if f.name == 'Processing'][0]\n",
    "mProcessing = mFolder / 'MGO_Model' / f'{dStr}'\n",
    "if mProcessing.exists() == True:\n",
    "    print(f'{mProcessing} already exist.')\n",
    "else:\n",
    "    mProcessing.mkdir(parents=True)\n",
    "    print(f'Created {mProcessing}.')\n",
    "\n",
    "mFR = [f for f in lPath if f.name == 'Review'][0]\n",
    "mReview = mFR / 'MGO_Model' / f'{dStr}'\n",
    "if mReview.exists() == True:\n",
    "    print(f'{mReview} already exist')\n",
    "else:\n",
    "    mReview.mkdir(parents=True)\n",
    "    print(f'Created {mReview}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GDB already exists.\n",
      "Daily_05_07 already exists\n",
      "MGO_05_07 Dataset has been created\n"
     ]
    }
   ],
   "source": [
    "iE = netDB / 'MAPPINGADMIN.sde' / 'PROD.MAPPINGADMIN.ParcelEditing'\n",
    "sr = arc.Describe(f'{iE}').spatialReference\n",
    "outGDB = gisPath / mFolder / f'Data_{mStr}.gdb'\n",
    "# dsA = gisPath / mFolder / f'{outGDB}.gdb'\n",
    "locGDB = outGDB / f'Daily_{dStr}'\n",
    "mgoGDB = outGDB / f'MGO_{dStr}'\n",
    "if arc.Exists(f'{outGDB}'):    \n",
    "    print(\"GDB already exists.\")\n",
    "else:\n",
    "    arc.CreateFileGDB_management(mFolder, f'{outGDB.name}')\n",
    "    print(f'Created File GeoDatabase at {outGDB.parent}')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "if arc.Exists(f'{locGDB}'):\n",
    "    print(f'{locGDB.name} already exists')\n",
    "else:\n",
    "    arc.CreateFeatureDataset_management(f'{locGDB.parent}', f'{locGDB.name}', sr)\n",
    "    print(f'{locGDB.name} Dataset has been created')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "if arc.Exists(f'{mgoGDB}'):\n",
    "    print(f'{mgoGDB.name} already exists')\n",
    "else:\n",
    "    arc.CreateFeatureDataset_management(f'{mgoGDB.parent}', f'{mgoGDB.name}', sr)\n",
    "    print(f'{mgoGDB.name} Dataset has been created')"
   ]
  },
  {
   "source": [
    "### Export Needed Feature Classes to Local GDB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbTaxParcels = \"PROD.GISADMIN.TaxParcels\"\n",
    "dbZoningPoly = \"PROD.PLANNINGADMIN.OfficialZoning\"\n",
    "dbApz = \"PROD.GISADMIN.APZ\"\n",
    "dbAgDist = \"PROD.GISADMIN.Ag_Districts\"\n",
    "dbAPFO = \"PROD.PLANNINGADMIN.APFO\"\n",
    "dbNoiseContour = \"PROD.GISADMIN.Noise_Contour_Area\"\n",
    "dbAirportZone = \"PROD.GISADMIN.Airport_Zones_onlyKentCounty\"\n",
    "dbAgEasement = \"PROD.GISADMIN.Ag_District_Easement\"\n",
    "dbAgExpansion = \"PROD.GISADMIN.AgDistrictExpansion\"\n",
    "dbAdd = 'PROD.ADDRESSINGADMIN.Addressing'\n",
    "dbSufP = 'PROD.GISADMIN.Suffix_Parcels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "APZ_05_07 has been copied\n",
      "Noise_Contour_Area_05_07 has been copied\n",
      "Airport_Zones_onlyKentCounty_05_07 has been copied\n",
      "AgDistrictExpansion_05_07 has been copied\n",
      "Ag_Districts_05_07 has been copied\n",
      "Ag_District_Easement_05_07 has been copied\n",
      "OfficialZoning_05_07 has been copied\n",
      "APFO_05_07 has been copied\n",
      "TaxParcels_05_07 has been copied\n",
      "Addressing_05_07 already exists\n",
      "Suffix_Parcels_05_07 already exists\n"
     ]
    }
   ],
   "source": [
    "#create paths to the data instead of using env.workspace makes it so that I can use arc Walk\n",
    "arc.env.workspace = f'{iE.parent}'\n",
    "\n",
    "mgoList = [dbTaxParcels, dbZoningPoly, dbApz, dbAgDist, dbAPFO, dbNoiseContour, dbAirportZone, dbAgEasement, dbAgExpansion]\n",
    "fcList = [dbAdd, dbSufP]\n",
    "mParcels = []\n",
    "cParcels = []\n",
    "for dirpath, dirnames, filenames in arc.da.Walk():\n",
    "    for f in filenames:\n",
    "        if f in mgoList:\n",
    "            a  = f.split('.')[-1]\n",
    "            b = f'{a}_{dStr}'\n",
    "            if arc.Exists(f'{mgoGDB / b}'):\n",
    "                mParcels.append(mgoGDB.joinpath(b))\n",
    "                print(f'{b} already exists')\n",
    "            else:\n",
    "                arc.FeatureClassToFeatureClass_conversion(f, f'{mgoGDB}', f'{b}')\n",
    "                mParcels.append(mgoGDB.joinpath(b))\n",
    "                print (f'{b} has been copied')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "for dirpath, dirnames, filenames in arc.da.Walk():\n",
    "    for f in filenames:\n",
    "        if f in fcList:\n",
    "            a  = f.split('.')[-1]\n",
    "            b = f'{a}_{dStr}'\n",
    "            if arc.Exists(f'{locGDB / b}'):\n",
    "                cParcels.append(locGDB.joinpath(b))\n",
    "                print(f'{b} already exists')\n",
    "            else:\n",
    "                arc.FeatureClassToFeatureClass_conversion(f, f'{locGDB}', f'{b}')\n",
    "                cParcels.append(locGDB.joinpath(b))\n",
    "                print (f'{b} has been copied')"
   ]
  },
  {
   "source": [
    "### Works with Parcel Fabric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ParcelFabric_Parcels_05_07 already exists\n"
     ]
    }
   ],
   "source": [
    "#currently using env.workspace to move parcelfabric needs to be changed to use path\n",
    "pfParcels = 'PROD.MAPPINGADMIN.ParcelFabric_Parcels'\n",
    "exp = \"TYPE = 7 AND Historical = 0\"\n",
    "a = pfParcels.split('.')[-1]\n",
    "b = f'{a}_{dStr}'\n",
    "# print(f'{iEPath[1]}')\n",
    "if arc.Exists(f'{locGDB / b}'):\n",
    "    cParcels.append(locGDB.joinpath(b))\n",
    "    print(f'{b} already exists')\n",
    "else:\n",
    "    print(f'Copying Parcel Fabric to {locGDB}')\n",
    "    #print(a)\n",
    "    # g = f'{f}'\n",
    "    #print(g)\n",
    "    arc.FeatureClassToFeatureClass_conversion(pfParcels, f'{locGDB}', b, where_clause=expr)\n",
    "    cParcels.append(locGDB.joinpath(b))\n",
    "    print(f'Finished Copying {b} to {locGDB}')"
   ]
  },
  {
   "source": [
    "### Create Spatial Joins with the exported Feature Classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Create Addressing DataFrame and create new address field for MGO."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Addressing Feature Clas from the MGO GDB\n",
    "gdbAdd = [f for f in cParcels if f.name.startswith('Addressing') == True][0]\n",
    "\n",
    "df_add = features.GeoAccessor.from_featureclass(gdbAdd)\n",
    "print('Address DataFrame created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_add['STS'].replace('None', \" \")\n",
    "# df_add.loc[df_add.STS == None, :]\n",
    "# df_add.isnull().sum()\n",
    "df_add['STS'].fillna(np.nan, inplace= True)\n",
    "df_add['STS'].replace(' ', '', inplace=True)\n",
    "df_add['STS'].replace(np.nan, '', inplace=True)\n",
    "# df_add['STS'].unique()\n",
    "# df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aType = df_add.STS.unique()\n",
    "# print(sType)\n",
    "for d in aType:\n",
    "    if d.upper() == 'ROAD':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'RD').strip())\n",
    "    elif d.upper() == 'DRIVE':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'DR').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'DR').strip())\n",
    "    elif d.upper() == 'BOULEVARD':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'BLVD').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'BLVD').strip())\n",
    "    elif d.upper() == 'LANE':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'LN').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'LN').strip())\n",
    "    elif d.upper() == 'COURT':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'CT').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'CT').strip())\n",
    "    elif d.upper() == 'CIRCLE':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'CIR').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'CIR').strip())\n",
    "    elif d.upper() == 'STREET':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'ST').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'ST').strip())\n",
    "    elif d.upper() == 'HIGHWAY':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'HWY').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'HWY').strip())\n",
    "    elif d.upper() == 'AVENUE':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'AVE').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'AVE').strip())\n",
    "    elif d.upper() == 'PLACE':\n",
    "        df_add.STS = df_add.STS.apply(lambda x: x.replace(d, 'PL').strip())\n",
    "        # sales_df['StreetType'] = sales_df.StreetType.apply(lambda x: x.replace(d, 'PL').strip())\n",
    "    else:\n",
    "        df_add.STS.str.strip()\n",
    "# print(df_add.STS.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add.fillna(np.nan, inplace= True)\n",
    "# df_add.replace(' ', '', inplace=True)\n",
    "df_add.replace(np.nan, '', inplace=True)\n",
    "# print(df_add.columns)\n",
    "# print(df_add.STS.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add.SAN = df_add.SAN.astype('str',errors='ignore')\n",
    "df_add.SAN = df_add.SAN.apply(lambda x: x.split('.')[0])\n",
    "df_add['FAddress'] = df_add[['SAN', 'PRD', 'STN', 'STS', 'POD']].values.tolist()\n",
    "# df_add.FAddress.values\n",
    "df_add['FooAddress'] = df_add['FAddress'].apply(' '.join)\n",
    "df_add['Address911'] = df_add['FooAddress'].apply(lambda x: ' '.join(x.split()))\n",
    "# df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_add.FAddress = df_add.FoAddress\n",
    "kColumns = ['Address911', 'SHAPE']\n",
    "# print([x for x in kColumns if x not in kColumns])\n",
    "df_add.drop(columns=[x for x in df_add if x not in kColumns], inplace=True)\n",
    "# df_add"
   ]
  },
  {
   "source": [
    "Create Tax Parcels DataFrame and join with Addressing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbTax = [f for f in mParcels if f.name.startswith('TaxParcels') == True][0]\n",
    "fTax = ['Name', 'Pride', 'Lot_Number', 'LOCATION', 'OWNERNAME', 'SECONDARYOWNER', 'MAILINGADDRESS', 'MAILINGADDRESS2', 'OWNERCITY', 'OWNERSTATE', 'OWNERZIP']\n",
    "arc.env.workspace = f'{mgoGDB}'\n",
    "dTaxC = [f.name for f in arc.ListFields(f'{gdbTax.name}') if f.name not in fTax]\n",
    "\n",
    "arc.DeleteField_management(f'{gdbTax}', dTaxC)\n",
    "arc.SpatialJoin_analysis(f'{gdbTax}', f'{gdbAdd}', f'{mgoGDB / \"Add_Join\"}')\n",
    "\n",
    "# tax_df = features.GeoAccessor.from_featureclass(gdbTax, fields=fTax)\n",
    "# print('TaxParcels DataFrame Created')"
   ]
  },
  {
   "source": [
    "# Remove Null Values from the SHAPE Column\n",
    "nParcels = mReview / 'Null_Parcels'\n",
    "tax_df.loc[tax_df.SHAPE.notnull()].to_csv(nParcels, index=False)\n",
    "df_tax = tax_df.loc[tax_df.SHAPE.notnull()]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_tax.spatial.join(df_add, how='left')\n",
    "# df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.loc[df_join['Address911'] == '1232 MEDIA RD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.Name == '1-17-01900-01-0102-00001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_df = df_join.loc[df_join.index_right.notnull()]\n",
    "at_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc.SpatialJoin_analysis(f'{gdbTax}', f'{gdbAdd}', f'{mgoGDB / \"Address_Join\"}')\n",
    "arc.GetCount_management(f'{mgoGDB / \"Address_Join\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.drop(columns='index_right', inplace=True)"
   ]
  },
  {
   "source": [
    "Join aiport zones with addressing join."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbAirZ = [f for f in mParcels if f.name.startswith('Airport_Zones') == True][0]\n",
    "\n",
    "az_df = features.GeoAccessor.from_featureclass(gdbAirZ, fields=['Airport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aza_join = df_join.spatial.join(az_df, how='left')\n",
    "aza_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(170384.875, 92243.48900000006, 208368.15479999967, 151648.81670000032)"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "aza_join.spatial.full_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbTax = [f for f in mParcels if f.name.startswith('TaxParcels') == True][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbTax = [f for f in mParcels if f.name.startswith('TaxParcels') == True][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0be568a45c5be0d4caf76dff1c2f5b3b93950ef2ed99d2899e809934a8a7c9d46",
   "display_name": "Python 3.7.10 64-bit ('arcNew': conda)"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}